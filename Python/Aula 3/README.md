# Aula 3 â€“ MÃ³dulos e Web Scraping (Python)

Nesta aula trabalhamos com **mÃ³dulos**, **funÃ§Ãµes** e **raspagem web (web scraping)**.  
Foram propostos 5 exercÃ­cios prÃ¡ticos para fixar os conteÃºdos.

---

## ğŸ“š ExercÃ­cios

### ExercÃ­cio 1 â€“ Cadastro de Alunas
- Gerar nomes fictÃ­cios de alunas (usando `faker`).
- Criar matrÃ­culas aleatÃ³rias (`random`).
- Salvar em `alunas.txt`.

### ExercÃ­cio 2 â€“ NÃºmeros AleatÃ³rios
- Gerar nÃºmeros aleatÃ³rios.
- Salvar em `numeros.txt`.

### ExercÃ­cio 3 â€“ Frases Motivacionais
- Criar um arquivo `frases.txt` com 31 frases (uma por dia).
- Usar leitura e escrita de arquivos.

### ExercÃ­cio 4 â€“ Criando um mÃ³dulo de utilidades (`arquivos.py`)
- FunÃ§Ãµes implementadas:
  - `contar_caracteres(nome_arquivo)` â†’ nÃºmero total de caracteres.
  - `contar_palavras(nome_arquivo)` â†’ nÃºmero de palavras.
  - `ler_conteudo(nome_arquivo, qtd_linhas)` â†’ primeiras N linhas.
- Testado em `teste_arquivos.py`.

### ExercÃ­cio 5 â€“ NÃ­vel AvanÃ§ado: Coletor de NotÃ­cias (`coletor.py`)
- Usa `requests` + `BeautifulSoup`.
- Coleta tÃ­tulo e texto de uma pÃ¡gina.
- Salva notÃ­cia em `noticia.txt`.
- Adiciona tÃ­tulos em `noticias.txt`.
- Mostra resumo no console.

---

## â–¶ï¸ Como executar, prÃ©-requisitos e estrutura
```bash
# executar
python teste_arquivos.py      # testa funÃ§Ãµes do arquivos.py
python coletor.py             # roda o coletor (versÃ£o simples)

# prÃ©-requisitos
pip install faker requests beautifulsoup4

# estrutura da pasta
Aula 3/
â”œâ”€ README.md
â”œâ”€ arquivos.py
â”œâ”€ teste_arquivos.py
â”œâ”€ coletor.py
â”œâ”€ alunas.txt
â”œâ”€ numeros.txt
â”œâ”€ frases.txt
â”œâ”€ noticia.txt
â”œâ”€ noticias.txt
â””â”€ relatorio.txt